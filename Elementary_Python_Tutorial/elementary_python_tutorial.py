# -*- coding: utf-8 -*-
"""Elementary_Python_Tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PIIC6X9pMj4wBTP954F9E1XOsKCiMzRs
"""

import numpy as np 
from scipy import linalg as LA
import pandas as pd
import random 
import matplotlib as mpl
import matplotlib.pyplot as plt

"""# Importing files from google drive

---

# Mounting Google Drive
We can access files in our google drive using mounting Google Drive, i.e., setting up the google drive account as a virtual drive. Thus we can access the resources of the drive like a local drive in our computer.

To connect Google Drive with Colab, we can execute the following two lines of code in Colab:
"""

from google.colab import drive
drive.mount("/content/gdrive")

"""# The dataset we are going to use is a simple regression task data from kaggle which can be downloaded from this link: 
https://www.kaggle.com/luddarell/101-simple-linear-regressioncsv

# Importing data from your google drive, assuming data is copied/pasted there

## (I have pastaed x.csv and y.csv files both in my google drive and in a folder named Python Tutorial in my google drive)

## Visualizing data in the form of dataframe (need "import pandas as pd")

#### The dataset is from kaggle: https://www.kaggle.com/mayanksrivastava/predict-housing-prices-simple-linear-regression

However we will not use this data. We just use it for introducing pandas dataframe which is great for visualization. And I'm using only 100 rows and some columns.
"""

# if data is copied in google drive
pd.read_csv('/content/gdrive/My Drive/Data.csv')[:5]

#if data is in a folder in your goole drive, use the following
pd.read_csv('/content/gdrive/My Drive/Python Tutorial/Data1.csv')

"""# Importing data from your computer
#### To import data execute the following two lines of code in Colab and then choose your data by browsing "Choose Files" botton.
"""

from google.colab import files
uploaded = files.upload()

pd.read_csv("Data.csv")[:5]

"""#Downloading Data from Colab into a Local Drive in Your Computer

We can download data into local directories by executing the following two lines of codes. Here we assume that the dataset is in CSV format.
"""

from google.colab import files

#if data is on the google drive
files.download('/content/gdrive/My Drive/Data.csv')

#if data is in a folder in google drive, use the following
files.download('/content/gdrive/My Drive/Python Tutorial/Data1.csv')

"""# $\bf Regression$

### We are going to do a simple regression task in order to be familier with some basic operations and fuctions needed in this course.

#### The first function we need is reading a file like a csv file.
"""

def read_file(file_name):
  data = []
  with open(file_name, "r") as f:
    for line in f:
      item = line.strip().split(",")
      data.append(np.array(item))
  return data

"""## Reading x and y values"""

data = read_file('/content/gdrive/My Drive/Data1.csv')[1:]

len(data)

random.shuffle(data)
data = np.array(data)

x_values = data[:,0]
y_values = data[:,1]

x = np.zeros(len(x_values))
for i in range(len(x_values)):
  x[i] = float(x_values[i])

x

y = np.zeros(len(y_values))
for i in range(len(y_values)):
  y[i] = float(y_values[i])

y

"""## Train/Test split of data (75/25%)"""

data_train = x[:63]
data_test = x[63:]

y_train = y[:63]
y_test = y[63:]

"""## Linear Regression
### Obtaining model parameters, i.e., $a$ and $b$ for the linear model $\ell(x) = a x + b$:

### $\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$, $\quad \overline{y} = \frac{1}{n} \sum_{i=1}^n y_i$, $\quad a = \langle \overline{x}, \overline{y}\rangle$, $\quad b = \overline{y} - a \cdot \overline{x}$

### $\overline{X} = (x_1-\overline{x}, \ldots, x_n-\overline{x})$, $\quad \overline{Y} = (x_1-\overline{y}, \ldots, x_n-\overline{y})$.
"""

x_bar = sum(data_train)/len(data_train)
y_bar = sum(y_train)/len(y_train)

X_bar = data_train - x_bar
Y_bar = y_train - y_bar

a = np.dot(X_bar, Y_bar)/LA.norm(X_bar)**2
b = y_bar - a * x_bar

a,b

"""## Calculating the residuals $r_i = y_i - \hat{y}_i$, where $\hat{y} = \ell(x_i) = ax_i+b$"""

y_hat = np.zeros(21)
for i in range(21):
  y_hat[i] = a * data_test[i] + b

r = y_test - y_hat #or y_hat - y_test

r

"""## Polynomial Regression
### $\tilde{X}_p$: Build the polynomial model with $p=2$: $\alpha = (\tilde{X}_p^T \tilde{X}_p)^{-1}\tilde{X}_p^Ty$
"""

X_p = np.ones((63, 3))
X_p[:,1] = data_train
X_p[:,2] = data_train**2
X_p[:4]

alpha = LA.inv(X_p.T @ X_p) @ X_p.T @ y_train
print('alpha =', alpha)

print('Model: M_5(x)=', alpha[0], '+', alpha[1], 'x', '+', alpha[2], 'x^2.')

"""# Plotting data and Models"""

plt.scatter(data_train, y_train);
plt.scatter(data_test, y_test, color = 'red');
plt.show()

def lin_reg(x):
  return a * x + b

def poly_reg(x):
  return alpha[0] + alpha[1] * x + alpha[2] * x**2

plt.scatter(data_train, y_train);
plt.scatter(data_test, y_test, color = 'red');

xlist = np.linspace(1600, 2100, 200)
plt.plot(xlist, lin_reg(xlist), 'purple')
plt.plot(xlist, poly_reg(xlist),'g')

plt.show()

"""# Gradien Descent"""

def func(x,y):
  return (x-1)**2 + (2*y-2)**2 + x * y

def func_grad(x,y):
  dfdx = 2*x - 2 + y
  dfdy = 8*y - 8 + x
  return np.array([dfdx,dfdy])

#prepare for contour plot
xlist = np.linspace(-5, 6, 50)
ylist = np.linspace(-2, 4, 50)
x, y = np.meshgrid(xlist, ylist)
z = func(x,y)
#lev = np.linspace(0,20,21)

#initialize location and settings
v_init = np.array([5,4])
num_iter = 10
values = np.zeros([num_iter,2])

values[0,:] = v_init
v = v_init

gamma = 0.1

# actual gradient descent algorithm
for i in range(1,num_iter):
  v = v - gamma * func_grad(v[0],v[1])
  values[i,:] = v

plt.contour(x,y,z,levels=lev)
plt.plot(values[:,0],values[:,1],'r-')
plt.plot(values[:,0],values[:,1],'bo')
grad_norm = LA.norm(func_grad(v[0],v[1]))
title = "gamma %0.2f | final grad %0.3f" % (gamma,grad_norm)
plt.title(title)
plt.show()

x = np.linspace(-6, 6, 50)
y = np.linspace(-3, 6, 50) 

X, Y = np.meshgrid(x, y)
Z = func(X, Y)

fig = plt.figure(figsize = (10, 6))
ax = plt.axes(projection='3d')
surface = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')
ax.set_title('function');

ax.scatter3D(values[:,0], values[:,1], func(values[:,0],values[:,1]), color = "red", s=100);

fig.colorbar(surface, shrink=1, aspect=10);
plt.show()

